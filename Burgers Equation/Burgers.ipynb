{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import scipy.io\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "plt.rcParams.update({                      # setup matplotlib to use latex for output\n",
    "    \"pgf.texsystem\": \"pdflatex\",        # change this if using xetex or lautex\n",
    "    \"text.usetex\": True,                # use LaTeX to write all text\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [],                   # blank entries should cause plots to inherit fonts from the document\n",
    "    \"font.sans-serif\": [],\n",
    "    \"font.monospace\": [],\n",
    "    \"figure.figsize\": (12,8),\n",
    "    \"axes.labelsize\": 12,               # LaTeX default is 10pt font.\n",
    "    \"font.size\": 11,\n",
    "    \"legend.fontsize\": 10,               # Make the legend/label fonts a little smaller\n",
    "    \"xtick.labelsize\": 10,\n",
    "    \"ytick.labelsize\": 10,\n",
    "    \"pgf.preamble\": [\n",
    "        r\"\\usepackage[utf8x]{inputenc}\",    # use utf8 fonts becasue your computer can handle it :)\n",
    "        r\"\\usepackage[T1]{fontenc}\",        # plots will be generated using this preamble\n",
    "        ]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-layer Perceptron\n",
    "class NN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        output_size,\n",
    "        depth,\n",
    "        act=torch.nn.Tanh,\n",
    "    ):\n",
    "        super(NN, self).__init__()\n",
    "        \n",
    "        layers = [('input', torch.nn.Linear(input_size, hidden_size))]\n",
    "        layers.append(('input_activation', act()))\n",
    "        for i in range(depth): \n",
    "            layers.append(\n",
    "                ('hidden_%d' % i, torch.nn.Linear(hidden_size, hidden_size))\n",
    "            )\n",
    "            layers.append(('activation_%d' % i, act()))\n",
    "        layers.append(('output', torch.nn.Linear(hidden_size, output_size)))\n",
    "\n",
    "        layerDict = OrderedDict(layers)\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net:\n",
    "    def __init__(self):\n",
    "        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "        self.model = NN(\n",
    "            input_size=2,\n",
    "            hidden_size=20,\n",
    "            output_size=1,\n",
    "            depth=4,\n",
    "            act=torch.nn.Tanh\n",
    "        ).to(device)\n",
    "        \n",
    "        self.h = 0.1\n",
    "        self.k = 0.1\n",
    "        x = torch.arange(-1, 1 + self.h, self.h)\n",
    "        t = torch.arange(0, 1 + self.k, self.k)\n",
    "\n",
    "        # exact solution\n",
    "        self.X = torch.stack(torch.meshgrid(x, t)).reshape(2, -1).T\n",
    "        \n",
    "        # training data\n",
    "        bc1 = torch.stack(torch.meshgrid(x[0], t)).reshape(2, -1).T\n",
    "        bc2 = torch.stack(torch.meshgrid(x[-1], t)).reshape(2, -1).T\n",
    "        ic = torch.stack(torch.meshgrid(x, t[0])).reshape(2, -1).T\n",
    "        self.X_train = torch.cat([bc1, bc2, ic])\n",
    "        y_bc1 = torch.zeros(len(bc1))\n",
    "        y_bc2 = torch.zeros(len(bc2))\n",
    "        y_ic = -torch.sin(math.pi * ic[:, 0])\n",
    "        self.y_train = torch.cat([y_bc1, y_bc2, y_ic])\n",
    "        self.y_train = self.y_train.unsqueeze(1)\n",
    "        \n",
    "        self.X = self.X.to(device)\n",
    "        self.X_train = self.X_train.to(device)\n",
    "        self.y_train = self.y_train.to(device)\n",
    "        self.X.requires_grad = True\n",
    "        \n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "        self.iter = 1\n",
    "        \n",
    "        self.optimizer = torch.optim.LBFGS(\n",
    "            self.model.parameters(), \n",
    "            lr=1.0, \n",
    "            max_iter=50000, \n",
    "            max_eval=50000, \n",
    "            history_size=50,\n",
    "            tolerance_grad=1e-5, \n",
    "            tolerance_change=1.0 * np.finfo(float).eps\n",
    "        )\n",
    "        \n",
    "        self.adam = torch.optim.Adam(self.model.parameters())\n",
    "        \n",
    "    def loss_func(self):\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = self.model(self.X_train)\n",
    "        loss_data = self.criterion(y_pred, self.y_train)\n",
    "\n",
    "        u = self.model(self.X)\n",
    "\n",
    "        du_dX = torch.autograd.grad(inputs=self.X, outputs=u, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        du_dt = du_dX[:, 1]\n",
    "        du_dx = du_dX[:, 0]\n",
    "        du_dxx = torch.autograd.grad(inputs=self.X, outputs=du_dX, grad_outputs=torch.ones_like(du_dX), retain_graph=True, create_graph=True)[0][:, 0]\n",
    "#         print(u.shape, du_dt.shape, du_dx.shape, du_dxx.shape)\n",
    "        loss_pde = self.criterion(du_dt + u.squeeze() * du_dx, 0.01 / math.pi * du_dxx)\n",
    "\n",
    "        loss = loss_pde + loss_data\n",
    "        loss.backward()\n",
    "        if self.iter % 100 == 0: \n",
    "            print(self.iter, loss.item())\n",
    "        self.iter = self.iter + 1\n",
    "        return loss\n",
    "    \n",
    "    def train(self):\n",
    "        for i in range(1000):\n",
    "            self.adam.step(self.loss_func)\n",
    "        self.optimizer.step(self.loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayroxis/.local/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.18140295147895813\n",
      "200 0.09370769560337067\n",
      "300 0.07628022134304047\n",
      "400 0.06667067855596542\n",
      "500 0.049526359885931015\n",
      "600 0.03457105904817581\n",
      "700 0.027608241885900497\n",
      "800 0.020747315138578415\n",
      "900 0.019751906394958496\n",
      "1000 0.0156443789601326\n",
      "1100 0.16815395653247833\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.01\n",
    "k = 0.01\n",
    "x = torch.arange(-1, 1, h)\n",
    "t = torch.arange(0, 1, k)\n",
    "\n",
    "# exact solution\n",
    "X = torch.stack(torch.meshgrid(x, t)).reshape(2, -1).T\n",
    "X = X.to(net.X.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net.model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X).reshape(len(x), len(t)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(y_pred, cmap='jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = {'v': y_pred}\n",
    "scipy.io.savemat('burgers_pinn.mat', mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
